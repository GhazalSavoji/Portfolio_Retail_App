{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfea5dc-2707-427b-b978-f300107f7dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The code below is for combining, cleaning, and resolving conflicts between two data sources:\n",
    "• User Mobile App Interaction Data – Kaggle\n",
    "• Online Retail II – UCI Machine Learning Repository\n",
    "\n",
    "This is for the Mobile App Retail portfolio project - Ghazal Savojbolaghi\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01992c53-cb58-4930-bc6e-d708cf276e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The code below is for combining, cleaning, and resolving conflicts between two data sources:\n",
    "• User Mobile App Interaction Data – Kaggle\n",
    "• Online Retail II – UCI Machine Learning Repository\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "mobile_app_path = r\"C:\\Users\\Ghazal Savoji\\Desktop\\Data Sample\\Create Database\\mobile_app_invoice_added.csv\"\n",
    "invoice_dates_path = r\"C:\\Users\\Ghazal Savoji\\Desktop\\Data Sample\\Create Database\\retail\\invoice_dates.csv\"\n",
    "\n",
    "# Read both CSVs\n",
    "df_mobile = pd.read_csv(mobile_app_path)\n",
    "df_invoice_dates = pd.read_csv(invoice_dates_path)\n",
    "\n",
    "# Ensure Invoice is the same type in both DataFrames\n",
    "df_mobile['Invoice'] = df_mobile['Invoice'].astype(str)\n",
    "df_invoice_dates['Invoice'] = df_invoice_dates['Invoice'].astype(str)\n",
    "\n",
    "# Merge only to know which invoices match\n",
    "df_merged = df_mobile.merge(df_invoice_dates[['Invoice']], on='Invoice', how='left', indicator=True)\n",
    "\n",
    "# Replace InvoiceDate only for matching invoices\n",
    "df_mobile.loc[df_merged['_merge'] == 'both', 'InvoiceDate'] = df_mobile.loc[df_merged['_merge'] == 'both', 'timestamp']\n",
    "\n",
    "# Save the updated file\n",
    "output_path = r\"C:\\Users\\Ghazal Savoji\\Desktop\\Data Sample\\Create Database\\mobile_app_invoice_updated.csv\"\n",
    "df_mobile.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\" Updated file saved successfully at:\\n{output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bba59196-a06b-4da5-8c77-ea2158b5808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generates 100,000 unique user IDs in the format 'u-XXXXXX-XXXX' where XXXXXX is a zero-padded 6-digit number and XXXX is a 4-character hex string.\n",
    "The IDs are saved to a CSV file.\"\"\"\n",
    "\n",
    "import secrets\n",
    "import random\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "N = 100000\n",
    "prefix = \"u\"\n",
    "\n",
    "ids = set()\n",
    "while len(ids) < N:\n",
    "    num = random.randint(0, 999999)  # 6-digit number (leading zeros)\n",
    "    hex_suffix = secrets.token_hex(1)  # 4 hex chars\n",
    "    uid = f\"{prefix}-{num:06d}-{hex_suffix}\"\n",
    "    ids.add(uid)\n",
    "\n",
    "ids_list = list(ids)\n",
    "out_path = Path(\"C:/Users/Ghazal Savoji/Desktop/user_ids.csv\")\n",
    "with out_path.open(\"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"user_id\"])\n",
    "    for uid in ids_list:\n",
    "        writer.writerow([uid])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252a9b47-1f0e-45ed-820b-47919a7a2f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generates 100,000 unique, cryptographically secure session IDs in the format\n",
    "'S-XXXXXX' where XXXXXX is a zero-padded 6-digit random number.\n",
    "The IDs are saved to a CSV file and a confirmation is printed.\n",
    "\"\"\"\n",
    "# generate_session_ids_secure.py\n",
    "import secrets\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "N = 100000\n",
    "out_path = Path(\"C:/Users/Ghazal Savoji/Desktop/session_ids_secure.csv\")\n",
    "\n",
    "ids = set()\n",
    "while len(ids) < N:\n",
    "    n = secrets.randbelow(10**6)   # 0..999999\n",
    "    ids.add(f\"S-{n:06d}\")\n",
    "\n",
    "session_ids = list(ids)\n",
    "\n",
    "with out_path.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"session_id\"])\n",
    "    for sid in session_ids:\n",
    "        writer.writerow([sid])\n",
    "\n",
    "print(f\"Saved {len(session_ids)} unique session IDs to: {out_path.resolve()}\")\n",
    "print(\"First 10 IDs:\", session_ids[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a92c898-4e73-40a7-9462-4a729236f362",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reads a mobile app interactions dataset, groups records by 'event_target' and\n",
    "'event_type', counts occurrences of each combination, prints the results,\n",
    "and saves them to a CSV file.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Ghazal Savoji\\Desktop\\Data Sample\\Create Database\\mobile_app_interactions_expanded.csv\")\n",
    "\n",
    "# Group by event_target and event_type and count occurrences of each combination\n",
    "event_counts = df.groupby(['event_target', 'event_type']).size().reset_index(name='count')\n",
    "\n",
    "# Display the result\n",
    "print(event_counts)\n",
    "\n",
    "# Save results to CSV\n",
    "output_path = r\"C:\\Users\\Ghazal Savoji\\Desktop\\event_counts.csv\"\n",
    "event_counts.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Results saved to file: '{output_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deb5e6b-4d72-4a6d-9a43-5cfd258c4c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reads a mobile app interactions dataset, filters records where 'event_target' is\n",
    "'home_page_banner', randomly samples 9,899 of these records, changes their\n",
    "'event_target' to 'checkout_button' and 'event_type' to 'click', then saves\n",
    "the modified sample to a new CSV file on the desktop.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Ghazal Savoji\\Desktop\\Data Sample\\Create Database\\mobile_app_interactions_expanded.csv\")\n",
    "\n",
    "# Filter records where event_target = home_page_banner\n",
    "banner_df = df[df['event_target'] == 'home_page_banner']\n",
    "\n",
    "# Select 9899 records randomly\n",
    "sample_df = banner_df.sample(n=9899, random_state=42)\n",
    "\n",
    "# Change event_target and event_type in the selected sample\n",
    "sample_df = sample_df.copy()\n",
    "sample_df['event_target'] = 'checkout_button'\n",
    "sample_df['event_type'] = 'click'\n",
    "\n",
    "# Save path on the desktop\n",
    "desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "output_file = os.path.join(desktop_path, \"home_banner_to_checkout.csv\")\n",
    "\n",
    "# Save to CSV\n",
    "sample_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Modified samples saved to file: '{output_file}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82646107-debe-4297-91da-e6c295696ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Combines multiple CSV files containing added/modified records into a single\n",
    "DataFrame, then saves the merged result as a new CSV file in the same directory.\n",
    "The script processes five specific files with 'to_checkout' transformations.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Folder path\n",
    "base_path = r\"C:\\Users\\Ghazal Savoji\\Desktop\\Data Sample\\Create Database\\added_records\"\n",
    "\n",
    "# List of files\n",
    "files = [\n",
    "    \"notification_to_checkout.csv\",\n",
    "    \"home_banner_to_checkout.csv\",\n",
    "    \"menu_icon_to_checkout.csv\",\n",
    "    \"search_bar_to_checkout.csv\",\n",
    "    \"post_video_to_checkout.csv\"\n",
    "]\n",
    "\n",
    "# Read and combine all files\n",
    "dfs = []\n",
    "for file in files:\n",
    "    file_path = os.path.join(base_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Merge all DataFrames\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Output path\n",
    "output_file = os.path.join(base_path, \"added_records.csv\")\n",
    "\n",
    "# Save to CSV\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"All records saved to file: '{output_file}'\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037d42b5-f181-436b-bd3c-f1f7d89341ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Combines two CSV files (original mobile app interactions dataset and the \n",
    "additional records file) into a single DataFrame, then saves the combined\n",
    "result as a new CSV file. This creates an enhanced dataset with all records.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# File paths\n",
    "file1 = r\"C:\\Users\\Ghazal Savoji\\Desktop\\Data Sample\\Create Database\\mobile_app_interactions_expanded.csv\"\n",
    "file2 = r\"C:\\Users\\Ghazal Savoji\\Desktop\\Data Sample\\Create Database\\added_records\\added_records.csv\"\n",
    "output_file = r\"C:\\Users\\Ghazal Savoji\\Desktop\\Data Sample\\Create Database\\mobile_app_records_added.csv\"\n",
    "\n",
    "# Read both CSV files\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "\n",
    "# Combine them\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Save to a new CSV file\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Combined CSV saved as: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139b18f8-5857-46da-b3d2-b327d5019add",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Reads the enhanced mobile app interactions dataset, filters records where \n",
    "'event_target' is 'checkout_button', randomly samples 25,900 of these records, \n",
    "changes their 'event_target' to 'thank_you_page' and 'event_type' to 'view', \n",
    "then saves the modified sample to a new CSV file on the desktop.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to the main file containing checkout_button records\n",
    "input_file = r\"C:\\Users\\Ghazal Savoji\\Desktop\\Data Sample\\Create Database\\mobile_app_records_added.csv\"\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Filter records where event_target = checkout_button\n",
    "checkout_df = df[df['event_target'] == 'checkout_button']\n",
    "\n",
    "# Select 25900 records randomly\n",
    "sample_df = checkout_df.sample(n=25900, random_state=42)\n",
    "\n",
    "# Change event_target and event_type in the selected sample\n",
    "sample_df = sample_df.copy()\n",
    "sample_df['event_target'] = 'thank_you_page'\n",
    "sample_df['event_type'] = 'view'\n",
    "\n",
    "# Save path on the desktop\n",
    "desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "output_file = os.path.join(desktop_path, \"thank_you_page_records.csv\")\n",
    "\n",
    "# Save to CSV\n",
    "sample_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Modified samples saved to file: '{output_file}'\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48e5fb7-3599-41c6-9a9c-5bd1518da45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Combines the enhanced mobile app interactions dataset with additional \n",
    "'thank_you_page' records, merging them into a single DataFrame and saving\n",
    "the result as a new CSV file. This creates the final dataset with all\n",
    "interactions including checkout conversions.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "file1 = r\"C:\\Users\\Ghazal Savoji\\Desktop\\Data Sample\\Create Database\\mobile_app_records_added.csv\"\n",
    "file2 = r\"C:\\Users\\Ghazal Savoji\\Desktop\\Data Sample\\Create Database\\added_records\\thank_you_page_records.csv\"\n",
    "output_file = r\"C:\\Users\\Ghazal Savoji\\Desktop\\Data Sample\\Create Database\\mobile_app_invoice_added.csv\"\n",
    "\n",
    "# Read both CSV files\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "\n",
    "# Combine them\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Save to a new CSV file\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Combined CSV saved as: {output_file}\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dd3e4e-1a09-4018-828c-1228ba871a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Splits a consolidated mobile app interactions dataset into four normalized \n",
    "tables (sessions, users, events, and device information) based on column \n",
    "groupings. Each table is saved as a separate CSV file for database import \n",
    "or further analysis.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the original CSV\n",
    "file_path = r\"C:\\Users\\Ghazal Savoji\\Desktop\\Data Sample\\Create Database\\mobile_app_invoice_added.csv\"\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define columns for each table\n",
    "sessions_cols = [\n",
    "    \"timestamp\", \"session_id\", \"session_duration_sec\", \"ip_address\", \n",
    "    \"network_type\", \"battery_level\", \"memory_usage_mb\", \"push_enabled\", \"user_id\"\n",
    "]\n",
    "\n",
    "users_cols = [\n",
    "    \"user_id\", \"location_country\", \"location_city\", \"is_subscribed\", \n",
    "    \"user_age\", \"phone_number\"\n",
    "]\n",
    "\n",
    "events_cols = [\n",
    "    \"timestamp\", \"user_id\", \"event_type\", \"event_target\", \n",
    "    \"event_value\", \"Invoice\", \"session_id\"\n",
    "]\n",
    "\n",
    "device_cols = [\n",
    "    \"device_os\", \"device_os_version\", \"device_model\", \"screen_resolution\", \n",
    "    \"app_language\", \"app_version\", \"user_id\"\n",
    "]\n",
    "\n",
    "# Create separate DataFrames for each table\n",
    "sessions_df = df[sessions_cols]\n",
    "users_df = df[users_cols]\n",
    "events_df = df[events_cols]\n",
    "device_df = df[device_cols]\n",
    "\n",
    "# Save each table to a separate CSV\n",
    "sessions_df.to_csv(r\"C:\\Users\\Ghazal Savoji\\Desktop\\Data Sample\\Create Database\\sessions.csv\", index=False)\n",
    "users_df.to_csv(r\"C:\\Users\\Ghazal Savoji\\Desktop\\Data Sample\\Create Database\\users.csv\", index=False)\n",
    "events_df.to_csv(r\"C:\\Users\\Ghazal Savoji\\Desktop\\Data Sample\\Create Database\\events.csv\", index=False)\n",
    "device_df.to_csv(r\"C:\\Users\\Ghazal Savoji\\Desktop\\Data Sample\\Create Database\\device.csv\", index=False)\n",
    "\n",
    "print(\"Tables have been successfully created and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dc97377-2f17-4e8b-8764-e32f4361f677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Invoice StockCode                          Description  Quantity  \\\n",
      "0  536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1  536365     71053                  WHITE METAL LANTERN         6   \n",
      "2  536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3  536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4  536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "           InvoiceDate  Price  Customer ID         Country  \n",
      "0  2024-12-01T08:26:00   2.55      17850.0  United Kingdom  \n",
      "1  2024-12-01T08:26:00   3.39      17850.0  United Kingdom  \n",
      "2  2024-12-01T08:26:00   2.75      17850.0  United Kingdom  \n",
      "3  2024-12-01T08:26:00   3.39      17850.0  United Kingdom  \n",
      "4  2024-12-01T08:26:00   3.39      17850.0  United Kingdom  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Reads an Excel file containing online retail transaction data, adjusts invoice\n",
    "dates by changing years (2010->2024, 2011->2025), converts dates to ISO 8601\n",
    "format, and saves the modified data to a new Excel file.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# File path\n",
    "file_path = r\"C:\\Users\\Ghazal Savoji\\Desktop\\Data Sample\\Create Database\\retail\\online_retail_II.xlsx\"\n",
    "\n",
    "# Read Excel file\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Convert date column to datetime\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], format='%m/%d/%Y %H:%M')\n",
    "\n",
    "# Function to change the year\n",
    "def adjust_year(dt):\n",
    "    if dt.year == 2010:\n",
    "        return dt.replace(year=2024)\n",
    "    elif dt.year == 2011:\n",
    "        return dt.replace(year=2025)\n",
    "    return dt\n",
    "\n",
    "# Apply function to entire column\n",
    "df['InvoiceDate'] = df['InvoiceDate'].apply(adjust_year)\n",
    "\n",
    "# Convert to ISO 8601 format (similar to \"2025-01-14T08:32:16\")\n",
    "df['InvoiceDate'] = df['InvoiceDate'].dt.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "# Display first few rows for verification\n",
    "print(df.head())\n",
    "\n",
    "# Save to new file if needed:\n",
    "output_path = r\"C:\\Users\\Ghazal Savoji\\Desktop\\Data Sample\\Create Database\\retail\\online_retail_II_modified.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8f7ccb-1e60-42f3-9b3a-a160b641d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Checks for data consistency in retail transaction data by verifying that\n",
    "each invoice has only one unique invoice date. Identifies and reports\n",
    "invoices with multiple different dates, saving problematic cases to a CSV file\n",
    "for further inspection.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# File path\n",
    "file_path = r\"C:\\Users\\Ghazal Savoji\\Desktop\\Data Sample\\Create Database\\retail\\online_retail_II_modified.xlsx\"\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Group by Invoice and check if all dates within each group are identical\n",
    "invoice_date_check = (\n",
    "    df.groupby('Invoice')['InvoiceDate']\n",
    "      .nunique()\n",
    "      .reset_index(name='UniqueDateCount')\n",
    ")\n",
    "\n",
    "# Find invoices that have more than one unique date\n",
    "invoices_with_multiple_dates = invoice_date_check[invoice_date_check['UniqueDateCount'] > 1]\n",
    "\n",
    "# Print result summary\n",
    "if invoices_with_multiple_dates.empty:\n",
    "    print(\"All invoices have consistent InvoiceDate values.\")\n",
    "else:\n",
    "    print(\" The following invoices have multiple different InvoiceDate values:\")\n",
    "    print(invoices_with_multiple_dates)\n",
    "\n",
    "# (Optional) Save problematic invoices to a CSV file for inspection\n",
    "output_path = r\"C:\\Users\\Ghazal Savoji\\Desktop\\Data Sample\\Create Database\\retail\\invoices_with_multiple_dates.csv\"\n",
    "invoices_with_multiple_dates.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558bfc14-8862-49d5-a77c-d0f333d90fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creates a reference file mapping each unique invoice to its corresponding date.\n",
    "Extracts only Invoice and InvoiceDate columns from retail transaction data,\n",
    "ensures consistent string format for invoice numbers, removes duplicates,\n",
    "and saves the clean mapping to a CSV file.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# Input file path\n",
    "file_path = r\"C:\\Users\\Ghazal Savoji\\Desktop\\Data Sample\\Create Database\\retail\\online_retail_II_modified.xlsx\"\n",
    "\n",
    "# Read Excel file\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Keep only Invoice and InvoiceDate columns\n",
    "df_subset = df[['Invoice', 'InvoiceDate']].copy()\n",
    "\n",
    "# Convert all Invoice values to string (to avoid int/str mix)\n",
    "df_subset['Invoice'] = df_subset['Invoice'].astype(str)\n",
    "\n",
    "# Remove duplicate invoices (keep the first occurrence)\n",
    "df_unique = df_subset.drop_duplicates(subset='Invoice')\n",
    "\n",
    "# Sort by Invoice (now all strings — safe)\n",
    "df_unique = df_unique.sort_values(by='Invoice')\n",
    "\n",
    "# Output file path (CSV)\n",
    "output_path = r\"C:\\Users\\Ghazal Savoji\\Desktop\\Data Sample\\Create Database\\retail\\invoice_dates.csv\"\n",
    "\n",
    "# Save to CSV\n",
    "df_unique.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\" CSV file created successfully at:\\n{output_path}\")\n",
    "print(df_unique.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b835b8-bcc3-4198-9887-7f7b7b75fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Splits CSV files into normalized database tables and loads them into a SQL Server database.\n",
    "Creates tables (if they don't exist) and imports data from CSV files for:\n",
    "- Users, Sessions, Events, Device (from mobile app interactions)\n",
    "- Retail (from online retail transactions)\n",
    "Handles data type conversions, NULL values, and schema enforcement.\n",
    "\"\"\"\n",
    "# Splitting csv files into tables which will be loaded to the database at SQL server\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import os\n",
    "import math\n",
    "\n",
    "# ----------------- Configuration -----------------\n",
    "SERVER = 'localhost'  # SQL Server instance\n",
    "DATABASE = 'MobileAppRetail_DB'\n",
    "SCHEMA = 'Behavior'\n",
    "CSV_FOLDER = r'B:\\Work\\job seeking 1404\\Data Sample\\Create Database\\Tables'\n",
    "\n",
    "# ----------------- Connect to SQL Server -----------------\n",
    "conn_str = (\n",
    "    f'DRIVER={{SQL Server}};'\n",
    "    f'SERVER={SERVER};'\n",
    "    f'DATABASE={DATABASE};'\n",
    "    f'Trusted_Connection=yes;'\n",
    ")\n",
    "conn = pyodbc.connect(conn_str)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# ----------------- Table definitions -----------------\n",
    "tables = {\n",
    "    \"Users\": {\n",
    "        \"columns\": [\n",
    "            \"user_id NVARCHAR(50) PRIMARY KEY\",\n",
    "            \"user_age INT NULL\",\n",
    "            \"is_subscribed BIT NULL\",\n",
    "            \"location_country NVARCHAR(100)\",\n",
    "            \"location_city NVARCHAR(100)\",\n",
    "            \"app_language NVARCHAR(50)\"\n",
    "        ],\n",
    "        \"csv\": \"users.csv\",\n",
    "        \"numeric_cols\": {\"user_age\": \"int\"},\n",
    "        \"bit_cols\": [\"is_subscribed\"]\n",
    "    },\n",
    "    \"Sessions\": {\n",
    "        \"columns\": [\n",
    "            \"session_id NVARCHAR(50) PRIMARY KEY\",\n",
    "            \"user_id NVARCHAR(50)\",\n",
    "            \"timestamp DATETIME NULL\",\n",
    "            \"session_duration_sec INT NULL\",\n",
    "            \"ip_address NVARCHAR(45)\",\n",
    "            \"network_type NVARCHAR(20)\",\n",
    "            \"battery_level INT NULL\",\n",
    "            \"memory_usage_mb INT NULL\",\n",
    "            \"push_enabled BIT NULL\"\n",
    "        ],\n",
    "        \"csv\": \"sessions.csv\",\n",
    "        \"numeric_cols\": {\"session_duration_sec\": \"int\", \"battery_level\": \"int\", \"memory_usage_mb\": \"int\"},\n",
    "        \"bit_cols\": [\"push_enabled\"]\n",
    "    },\n",
    "    \"Events\": {\n",
    "        \"columns\": [\n",
    "            \"event_id NVARCHAR(50) PRIMARY KEY\",\n",
    "            \"session_id NVARCHAR(50)\",\n",
    "            \"event_type NVARCHAR(50)\",\n",
    "            \"event_target NVARCHAR(50)\",\n",
    "            \"event_value NVARCHAR(100)\"\n",
    "        ],\n",
    "        \"csv\": \"events.csv\",\n",
    "        \"numeric_cols\": {},\n",
    "        \"bit_cols\": []\n",
    "    },\n",
    "    \"Device\": {\n",
    "        \"columns\": [\n",
    "            \"device_id NVARCHAR(50) PRIMARY KEY\",\n",
    "            \"user_id NVARCHAR(50)\",\n",
    "            \"device_os NVARCHAR(20)\",\n",
    "            \"device_os_version NVARCHAR(20)\",\n",
    "            \"device_model NVARCHAR(50)\",\n",
    "            \"screen_resolution NVARCHAR(20)\",\n",
    "            \"app_version NVARCHAR(20)\"\n",
    "        ],\n",
    "        \"csv\": \"device.csv\",\n",
    "        \"numeric_cols\": {},\n",
    "        \"bit_cols\": []\n",
    "    },\n",
    "    \"Retail\": {\n",
    "        \"columns\": [\n",
    "            \"invoice_id NVARCHAR(50) PRIMARY KEY\",\n",
    "            \"user_id NVARCHAR(50)\",\n",
    "            \"session_id NVARCHAR(50)\",\n",
    "            \"stock_code NVARCHAR(50)\",\n",
    "            \"description NVARCHAR(100)\",\n",
    "            \"quantity INT NULL\",\n",
    "            \"price DECIMAL(10,2) NULL\",\n",
    "            \"invoice_date DATETIME NULL\",\n",
    "            \"country NVARCHAR(50)\",\n",
    "            \"customer_id NVARCHAR(50)\"\n",
    "        ],\n",
    "        \"csv\": \"retail.csv\",\n",
    "        \"numeric_cols\": {\"quantity\": \"int\", \"price\": \"float\"},\n",
    "        \"bit_cols\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "# ----------------- Import process -----------------\n",
    "for table_name, table_info in tables.items():\n",
    "    print(f\" Processing table {table_name}...\")\n",
    "\n",
    "    # Create table if it doesn't exist\n",
    "    columns_sql = \", \".join(table_info[\"columns\"])\n",
    "    create_table_sql = f'''\n",
    "    IF NOT EXISTS (SELECT * FROM INFORMATION_SCHEMA.TABLES \n",
    "                   WHERE TABLE_SCHEMA = '{SCHEMA}' AND TABLE_NAME = '{table_name}')\n",
    "    BEGIN\n",
    "        CREATE TABLE {SCHEMA}.{table_name} ({columns_sql})\n",
    "    END\n",
    "    '''\n",
    "    cursor.execute(create_table_sql)\n",
    "    conn.commit()\n",
    "\n",
    "    # Read CSV\n",
    "    csv_path = os.path.join(CSV_FOLDER, table_info[\"csv\"])\n",
    "    df = pd.read_csv(csv_path, encoding='utf-8')\n",
    "\n",
    "    # Clean numeric columns safely\n",
    "    for col, col_type in table_info[\"numeric_cols\"].items():\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')  # invalid → NaN\n",
    "            def safe_number(x):\n",
    "                if pd.isna(x) or not math.isfinite(x):\n",
    "                    return None\n",
    "                return int(x) if col_type == \"int\" else float(x)\n",
    "            df[col] = df[col].apply(safe_number)\n",
    "\n",
    "    # Clean BIT columns\n",
    "    for col in table_info[\"bit_cols\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(lambda x: 1 if str(x).strip().upper() in [\"1\",\"TRUE\",\"YES\"] \n",
    "                                    else 0 if str(x).strip().upper() in [\"0\",\"FALSE\",\"NO\"] \n",
    "                                    else None)\n",
    "\n",
    "    # Prepare insert\n",
    "    cols = [col.split()[0] for col in table_info[\"columns\"]]\n",
    "    placeholders = \", \".join([\"?\"] * len(cols))\n",
    "    insert_sql = f\"INSERT INTO {SCHEMA}.{table_name} ({', '.join(cols)}) VALUES ({placeholders})\"\n",
    "\n",
    "    # Insert rows\n",
    "    for _, row in df.iterrows():\n",
    "        values = [row.get(col) if col in df.columns else None for col in cols]\n",
    "        cursor.execute(insert_sql, values)\n",
    "    conn.commit()\n",
    "    print(f\" Data for table {table_name} imported successfully!\")\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(\" All data imported into MobileAppRetail_DB successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f14138-1626-4023-8fe0-f5209282cab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
